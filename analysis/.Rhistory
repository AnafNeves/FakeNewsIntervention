df_wide <- df_wide %>%
mutate(across(contains("Pretest_") | contains("Posttest_"),
~ case_when(
str_detect(cur_column(), "real") & . >= 50 ~ 1,
str_detect(cur_column(), "fake") & . < 50 ~ 1,
TRUE ~ 0
),
.names = "{.col}_binary"))
# 1. Overall accuracy rate per participant (binary)
dfmist_summary_participant <- dfmist %>%
rowwise() %>%
mutate(overall_accuracy = sum(across(ends_with("_binary")), na.rm = TRUE) / sum(!is.na(across(ends_with("_binary")))))
# 2. Accuracy rate per participant for Pretest
dfmist_summary_participant_pre <- dfmist %>%
rowwise() %>%
mutate(pretest_accuracy = sum(across(starts_with("Pretest_"), ends_with("_binary")), na.rm = TRUE) / sum(!is.na(across(starts_with("Pretest_"), ends_with("_binary")))))
rm(dfmist_summary_participant_post)
rm(dfmist_summary_participant)
# 1. Overall accuracy rate per participant (binary) in df_wide
df_wide_summary_participant <- df_wide %>%
rowwise() %>%
mutate(overall_accuracy = sum(across(ends_with("_binary")), na.rm = TRUE) / sum(!is.na(across(ends_with("_binary")))))
# 2. Accuracy rate per participant for Pretest in df_wide
df_wide_summary_participant_pre <- df_wide %>%
rowwise() %>%
mutate(pretest_accuracy = sum(across(starts_with("Pretest_"), ends_with("_binary")), na.rm = TRUE) / sum(!is.na(across(starts_with("Pretest_"), ends_with("_binary")))))
# 1. Overall accuracy rate per participant (binary) in df_wide
df_wide_summary_participant <- df_wide %>%
rowwise() %>%
mutate(overall_accuracy = sum(across(ends_with("_binary")), na.rm = TRUE) / sum(!is.na(across(ends_with("_binary")))))
# 2. Accuracy rate per participant for Pretest in df_wide
df_wide_summary_participant_pre <- df_wide %>%
rowwise() %>%
mutate(pretest_accuracy = sum(across(starts_with("Pretest_") & ends_with("_binary")), na.rm = TRUE) / sum(!is.na(across(starts_with("Pretest_") & ends_with("_binary")))))
# 3. Accuracy rate per participant for Posttest in df_wide
df_wide_summary_participant_post <- df_wide %>%
rowwise() %>%
mutate(posttest_accuracy = sum(across(starts_with("Posttest_") & ends_with("_binary")), na.rm = TRUE) / sum(!is.na(across(starts_with("Posttest_") & ends_with("_binary")))))
# 4. Effect size: difference between pretest and posttest accuracy
df_wide_summary_participant <- df_wide_summary_participant %>%
left_join(df_wide_summary_participant_pre %>%
select(Participant, pretest_accuracy), by = "Participant") %>%
left_join(df_wide_summary_participant_post %>%
select(Participant, posttest_accuracy), by = "Participant") %>%
mutate(effect_size = posttest_accuracy - pretest_accuracy)
# View the summary table
df_wide_summary_participant
# 1. Add overall accuracy rate per participant (binary)
df_wide <- df_wide %>%
rowwise() %>%
mutate(overall_accuracy = sum(across(ends_with("_binary")), na.rm = TRUE) / sum(!is.na(across(ends_with("_binary")))))
# 2. Add accuracy rate for Pretest (binary)
df_wide <- df_wide %>%
rowwise() %>%
mutate(pretest_accuracy = sum(across(starts_with("Pretest_") & ends_with("_binary")), na.rm = TRUE) / sum(!is.na(across(starts_with("Pretest_") & ends_with("_binary")))))
# 3. Add accuracy rate for Posttest (binary)
df_wide <- df_wide %>%
rowwise() %>%
mutate(posttest_accuracy = sum(across(starts_with("Posttest_") & ends_with("_binary")), na.rm = TRUE) / sum(!is.na(across(starts_with("Posttest_") & ends_with("_binary")))))
# 4. Calculate the effect size (difference between posttest and pretest accuracy)
df_wide <- df_wide %>%
mutate(effect_size = posttest_accuracy - pretest_accuracy)
# View the updated df_wide with new columns
head(df_wide)
write.csv(df_wide, "df_wide_summary.csv", row.names = FALSE)
df_wide <- df_wide %>%
mutate(across(ends_with("_binary"),
~ case_when(
. == 1 ~ abs(get(str_replace(cur_column(), "_binary", "")) - 50), # Confidence for correct answers
. == 0 ~ abs(get(str_replace(cur_column(), "_binary", "")) - 50) # Confidence for incorrect answers (same formula for now)
), .names = "{.col}_confidence"))
# Now df_wide should have new confidence columns based on the binary columns for each question
write.csv(df_wide, "df_wide_confidence.csv", row.names = FALSE)
df_wide_confidence <- df_wide %>%
# Pretest: Average confidence for correctly answered questions
mutate(
pretest_correct_confidence = rowMeans(select(., starts_with("Pretest") & ends_with("binary_confidence"))[df_wide_confidence[starts_with("Pretest") & ends_with("binary_confidence")] == 1], na.rm = TRUE),
# Pretest: Average confidence for incorrectly answered questions
pretest_incorrect_confidence = rowMeans(select(., starts_with("Pretest") & ends_with("binary_confidence"))[df_wide_confidence[starts_with("Pretest") & ends_with("binary_confidence")] == 0], na.rm = TRUE),
# Pretest: Overall average confidence for all pretest questions
pretest_overall_confidence = rowMeans(select(., starts_with("Pretest") & ends_with("binary_confidence")), na.rm = TRUE),
# Posttest: Average confidence for correctly answered questions
posttest_correct_confidence = rowMeans(select(., starts_with("Posttest") & ends_with("binary_confidence"))[df_wide_confidence[starts_with("Posttest") & ends_with("binary_confidence")] == 1], na.rm = TRUE),
# Posttest: Average confidence for incorrectly answered questions
posttest_incorrect_confidence = rowMeans(select(., starts_with("Posttest") & ends_with("binary_confidence"))[df_wide_confidence[starts_with("Posttest") & ends_with("binary_confidence")] == 0], na.rm = TRUE),
# Posttest: Overall average confidence for all posttest questions
posttest_overall_confidence = rowMeans(select(., starts_with("Posttest") & ends_with("binary_confidence")), na.rm = TRUE)
)
# Create the new columns in df_wide
df_wide_confidence <- df_wide %>%
# Pretest: Average confidence for correctly answered questions
mutate(
pretest_correct_confidence = rowMeans(select(., starts_with("Pretest") & ends_with("binary_confidence"))[df_wide[starts_with("Pretest") & ends_with("binary_confidence")] == 1], na.rm = TRUE),
# Pretest: Average confidence for incorrectly answered questions
pretest_incorrect_confidence = rowMeans(select(., starts_with("Pretest") & ends_with("binary_confidence"))[df_wide[starts_with("Pretest") & ends_with("binary_confidence")] == 0], na.rm = TRUE),
# Pretest: Overall average confidence for all pretest questions
pretest_overall_confidence = rowMeans(select(., starts_with("Pretest") & ends_with("binary_confidence")), na.rm = TRUE),
# Posttest: Average confidence for correctly answered questions
posttest_correct_confidence = rowMeans(select(., starts_with("Posttest") & ends_with("binary_confidence"))[df_wide[starts_with("Posttest") & ends_with("binary_confidence")] == 1], na.rm = TRUE),
# Posttest: Average confidence for incorrectly answered questions
posttest_incorrect_confidence = rowMeans(select(., starts_with("Posttest") & ends_with("binary_confidence"))[df_wide[starts_with("Posttest") & ends_with("binary_confidence")] == 0], na.rm = TRUE),
# Posttest: Overall average confidence for all posttest questions
posttest_overall_confidence = rowMeans(select(., starts_with("Posttest") & ends_with("binary_confidence")), na.rm = TRUE)
)
df_wide <- df_wide %>%
# Calculate the average confidence for pretest questions answered correctly
mutate(
pretest_correct_confidence = rowMeans(
select(., starts_with("Pretest") & ends_with("binary_confidence"))[
select(., starts_with("Pretest") & ends_with("binary_confidence")) == 1
], na.rm = TRUE
),
# Calculate the average confidence for pretest questions answered incorrectly
pretest_incorrect_confidence = rowMeans(
select(., starts_with("Pretest") & ends_with("binary_confidence"))[
select(., starts_with("Pretest") & ends_with("binary_confidence")) == 0
], na.rm = TRUE
),
# Calculate the average confidence for all pretest questions
pretest_overall_confidence = rowMeans(
select(., starts_with("Pretest") & ends_with("binary_confidence")), na.rm = TRUE
),
# Calculate the average confidence for posttest questions answered correctly
posttest_correct_confidence = rowMeans(
select(., starts_with("Posttest") & ends_with("binary_confidence"))[
select(., starts_with("Posttest") & ends_with("binary_confidence")) == 1
], na.rm = TRUE
),
# Calculate the average confidence for posttest questions answered incorrectly
posttest_incorrect_confidence = rowMeans(
select(., starts_with("Posttest") & ends_with("binary_confidence"))[
select(., starts_with("Posttest") & ends_with("binary_confidence")) == 0
], na.rm = TRUE
),
# Calculate the average confidence for all posttest questions
posttest_overall_confidence = rowMeans(
select(., starts_with("Posttest") & ends_with("binary_confidence")), na.rm = TRUE
)
)
df_wide <- df_wide %>%
# Calculate the average confidence for pretest questions answered correctly
mutate(
pretest_correct_confidence = rowMeans(
select(df_wide, starts_with("Pretest") & ends_with("binary_confidence"))[
, which(select(df_wide, starts_with("Pretest") & ends_with("binary_confidence")) == 1)
], na.rm = TRUE
),
# Calculate the average confidence for pretest questions answered incorrectly
pretest_incorrect_confidence = rowMeans(
select(df_wide, starts_with("Pretest") & ends_with("binary_confidence"))[
, which(select(df_wide, starts_with("Pretest") & ends_with("binary_confidence")) == 0)
], na.rm = TRUE
),
# Calculate the average confidence for all pretest questions
pretest_overall_confidence = rowMeans(
select(df_wide, starts_with("Pretest") & ends_with("binary_confidence")), na.rm = TRUE
),
# Calculate the average confidence for posttest questions answered correctly
posttest_correct_confidence = rowMeans(
select(df_wide, starts_with("Posttest") & ends_with("binary_confidence"))[
, which(select(df_wide, starts_with("Posttest") & ends_with("binary_confidence")) == 1)
], na.rm = TRUE
),
# Calculate the average confidence for posttest questions answered incorrectly
posttest_incorrect_confidence = rowMeans(
select(df_wide, starts_with("Posttest") & ends_with("binary_confidence"))[
, which(select(df_wide, starts_with("Posttest") & ends_with("binary_confidence")) == 0)
], na.rm = TRUE
),
# Calculate the average confidence for all posttest questions
posttest_overall_confidence = rowMeans(
select(df_wide, starts_with("Posttest") & ends_with("binary_confidence")), na.rm = TRUE
)
)
df_wide <- df_wide %>%
mutate(
pretest_correct_confidence = rowMeans(
select(df_wide, starts_with("Pretest") & ends_with("binary_confidence")) *
ifelse(select(df_wide, starts_with("Pretest") & ends_with("binary")) == 1, 1, 0),
na.rm = TRUE
),
pretest_incorrect_confidence = rowMeans(
select(df_wide, starts_with("Pretest") & ends_with("binary_confidence")) *
ifelse(select(df_wide, starts_with("Pretest") & ends_with("binary")) == 0, 1, 0),
na.rm = TRUE
),
pretest_overall_confidence = rowMeans(
select(df_wide, starts_with("Pretest") & ends_with("binary_confidence")),
na.rm = TRUE
),
posttest_correct_confidence = rowMeans(
select(df_wide, starts_with("Posttest") & ends_with("binary_confidence")) *
ifelse(select(df_wide, starts_with("Posttest") & ends_with("binary")) == 1, 1, 0),
na.rm = TRUE
),
posttest_incorrect_confidence = rowMeans(
select(df_wide, starts_with("Posttest") & ends_with("binary_confidence")) *
ifelse(select(df_wide, starts_with("Posttest") & ends_with("binary")) == 0, 1, 0),
na.rm = TRUE
),
posttest_overall_confidence = rowMeans(
select(df_wide, starts_with("Posttest") & ends_with("binary_confidence")),
na.rm = TRUE
)
)
df_wide <- df_wide %>%
mutate(
# Correct confidence scores (pretest)
pretest_correct_confidence = rowMeans(
select(df_wide, starts_with("Pretest") & ends_with("binary_confidence")) *
ifelse(select(df_wide, starts_with("Pretest") & ends_with("binary")) == 1, 1, 0),
na.rm = TRUE
),
# Incorrect confidence scores (pretest)
pretest_incorrect_confidence = rowMeans(
select(df_wide, starts_with("Pretest") & ends_with("binary_confidence")) *
ifelse(select(df_wide, starts_with("Pretest") & ends_with("binary")) == 0, 1, 0),
na.rm = TRUE
),
# Overall confidence (pretest)
pretest_overall_confidence = rowMeans(
select(df_wide, starts_with("Pretest") & ends_with("binary_confidence")),
na.rm = TRUE
),
# Correct confidence scores (posttest)
posttest_correct_confidence = rowMeans(
select(df_wide, starts_with("Posttest") & ends_with("binary_confidence")) *
ifelse(select(df_wide, starts_with("Posttest") & ends_with("binary")) == 1, 1, 0),
na.rm = TRUE
),
# Incorrect confidence scores (posttest)
posttest_incorrect_confidence = rowMeans(
select(df_wide, starts_with("Posttest") & ends_with("binary_confidence")) *
ifelse(select(df_wide, starts_with("Posttest") & ends_with("binary")) == 0, 1, 0),
na.rm = TRUE
),
# Overall confidence (posttest)
posttest_overall_confidence = rowMeans(
select(df_wide, starts_with("Posttest") & ends_with("binary_confidence")),
na.rm = TRUE
)
)
df_wide <- df_wide %>%
# Correct confidence scores for pretest (answered correctly)
mutate(
pretest_correct_confidence = rowMeans(
select(df_wide, starts_with("Pretest") & ends_with("binary_confidence")) *
(select(df_wide, starts_with("Pretest") & ends_with("binary")) == 1),
na.rm = TRUE
),
# Incorrect confidence scores for pretest (answered incorrectly)
pretest_incorrect_confidence = rowMeans(
select(df_wide, starts_with("Pretest") & ends_with("binary_confidence")) *
(select(df_wide, starts_with("Pretest") & ends_with("binary")) == 0),
na.rm = TRUE
),
# Overall confidence scores for pretest (all answers, not based on correctness)
pretest_overall_confidence = rowMeans(
select(df_wide, starts_with("Pretest") & ends_with("binary_confidence")),
na.rm = TRUE
),
# Correct confidence scores for posttest (answered correctly)
posttest_correct_confidence = rowMeans(
select(df_wide, starts_with("Posttest") & ends_with("binary_confidence")) *
(select(df_wide, starts_with("Posttest") & ends_with("binary")) == 1),
na.rm = TRUE
),
# Incorrect confidence scores for posttest (answered incorrectly)
posttest_incorrect_confidence = rowMeans(
select(df_wide, starts_with("Posttest") & ends_with("binary_confidence")) *
(select(df_wide, starts_with("Posttest") & ends_with("binary")) == 0),
na.rm = TRUE
),
# Overall confidence scores for posttest (all answers, not based on correctness)
posttest_overall_confidence = rowMeans(
select(df_wide, starts_with("Posttest") & ends_with("binary_confidence")),
na.rm = TRUE
)
)
#| message: false
#| warning: false
library(tidyverse)
library(easystats)
library(patchwork)
library(ggside)
library(modelsummary)
#| code-fold: false
df <- read.csv("../data/rawdata.csv")  |>
mutate(Intervention = ifelse(!is.na(Badnews_Questions_Duration), "BadNews", "Tetris")) |>
select(-Prolific_ID, -Date_OSF, -BadNews_Duration)
#| code-fold: false
df <- read.csv("../data/rawdata.csv")  |>
select(-Prolific_ID, -Date_OSF)
#| code-fold: false
df <- read.csv("../data/rawdata.csv")  |>
dfmist <- read.csv("../data/rawdata_mist.csv")
#| code-fold: false
df <- read.csv("../data/rawdata.csv")
dfmist <- read.csv("../data/rawdata_mist.csv")
# Ensure 'Intervention_Questions_Score' is numeric and remove invalid rows
df$Intervention_Questions_Score <- as.numeric(df$Intervention_Questions_Score)
df_clean <- na.omit(df)  # Remove rows with NA in any column
# Generate summary statistics with modelsummary
library(modelsummary)
datasummary_skim(df_clean ~ Intervention)
# Ensure 'Intervention_Questions_Score' is numeric and remove invalid rows
df$Intervention_Questions_Score <- as.numeric(df$Intervention_Questions_Score)
df_clean <- na.omit(df)  # Remove rows with NA in any column
# Generate summary statistics with modelsummary (corrected usage)
library(modelsummary)
datasummary_skim(df_clean, by = "Intervention")
# Ensure 'Intervention_Questions_Score' is numeric and remove invalid rows
df$Intervention_Questions_Score <- as.numeric(df$Intervention_Questions_Score)
df_clean <- na.omit(df)  # Remove rows with NA in any column
# Generate summary statistics with modelsummary (corrected usage)
library(modelsummary)
datasummary_skim(Intervention_Questions_Score ~ Intervention, data = df_clean)
# Ensure 'Intervention_Questions_Score' is numeric and remove invalid rows
df$Intervention_Questions_Score <- as.numeric(df$Intervention_Questions_Score)
df_clean <- na.omit(df)  # Remove rows with NA in any column
# Generate summary statistics for 'Intervention_Questions_Score' grouped by 'Intervention'
library(modelsummary)
datasummary_skim(df_clean[, c("Intervention_Questions_Score", "Intervention")])
# Ensure 'Intervention_Questions_Score' is numeric and remove invalid rows
df$Intervention_Questions_Score <- as.numeric(df$Intervention_Questions_Score)
df_clean <- na.omit(df)  # Remove rows with NA in any column
# Generate summary statistics for 'Intervention_Questions_Score' by 'Intervention'
library(modelsummary)
summary_stats <- modelsummary::datasummary_skim(df_clean[, c("Intervention_Questions_Score", "Intervention")], output = "data.frame")
# Display the summary as a clean dataframe
print(summary_stats)
# Ensure 'Intervention_Questions_Score' is numeric and remove invalid rows
df$Intervention_Questions_Score <- as.numeric(df$Intervention_Questions_Score)
df_clean <- na.omit(df)  # Remove rows with NA in any column
# Generate summary statistics for 'Intervention_Questions_Score' by 'Intervention'
library(dplyr)
summary_stats <- df_clean %>%
group_by(Intervention) %>%
summarise(
Mean = mean(Intervention_Questions_Score, na.rm = TRUE),
SD = sd(Intervention_Questions_Score, na.rm = TRUE),
Min = min(Intervention_Questions_Score, na.rm = TRUE),
Max = max(Intervention_Questions_Score, na.rm = TRUE)
)
# Display the summary statistics
print(summary_stats)
# Ensure 'Intervention_Questions_Score' is numeric and remove invalid rows
df$Intervention_Questions_Score <- as.numeric(df$Intervention_Questions_Score)
df_clean <- na.omit(df)  # Remove rows with NA in any column
# Generate summary statistics for 'Intervention_Questions_Score' by 'Intervention'
library(dplyr)
summary_stats <- df_clean %>%
group_by(Intervention) %>%
summarise(
Mean = mean(Intervention_Questions_Score, na.rm = TRUE),
SD = sd(Intervention_Questions_Score, na.rm = TRUE),
Min = min(Intervention_Questions_Score, na.rm = TRUE),
Max = max(Intervention_Questions_Score, na.rm = TRUE)
)
# Display the summary statistics
print(summary_stats)
# Compute the mean and SD for each group
summary_stats <- df_clean %>%
group_by(Intervention) %>%
summarise(
Mean = mean(Intervention_Questions_Score, na.rm = TRUE),
SD = sd(Intervention_Questions_Score, na.rm = TRUE)
)
# Merge the summary statistics back with the original data
df_clean <- df_clean %>%
left_join(summary_stats, by = "Intervention") %>%
mutate(
Is_Outlier = Intervention_Questions_Score < (Mean - 2 * SD) | Intervention_Questions_Score > (Mean + 2 * SD)
) %>%
select(-Mean, -SD)  # Remove the temporary mean and SD columns
# Check the data with identified outliers
print(head(df_clean))
# Ensure 'Intervention_Questions_Score' is numeric and remove invalid rows
df$Intervention_Questions_Score <- as.numeric(df$Intervention_Questions_Score)
df_clean <- na.omit(df)  # Remove rows with NA in any column
# Generate summary statistics for 'Intervention_Questions_Score' by 'Intervention'
library(dplyr)
summary_stats <- df_clean %>%
group_by(Intervention) %>%
summarise(
Mean = mean(Intervention_Questions_Score, na.rm = TRUE),
SD = sd(Intervention_Questions_Score, na.rm = TRUE),
Min = min(Intervention_Questions_Score, na.rm = TRUE),
Max = max(Intervention_Questions_Score, na.rm = TRUE)
)
# Display the summary statistics
print(summary_stats)
# Compute the mean and SD for each group
summary_stats <- df_clean %>%
group_by(Intervention) %>%
summarise(
Mean = mean(Intervention_Questions_Score, na.rm = TRUE),
SD = sd(Intervention_Questions_Score, na.rm = TRUE)
)
# Merge the summary statistics back with the original data
df_clean <- df_clean %>%
left_join(summary_stats, by = "Intervention") %>%
mutate(
Is_Outlier = Intervention_Questions_Score < (Mean - 2 * SD) | Intervention_Questions_Score > (Mean + 2 * SD)
) %>%
select(-Mean, -SD)  # Remove the temporary mean and SD columns
# Filter rows where Is_Outlier is TRUE
outliers <- df_clean %>%
filter(Is_Outlier == TRUE)
# Print the outliers
print(outliers)
# Ensure 'Intervention_Questions_Score' is numeric and remove invalid rows
df$Intervention_Questions_Score <- as.numeric(df$Intervention_Questions_Score)
df_clean <- na.omit(df)  # Remove rows with NA in any column
# Generate summary statistics for 'Intervention_Questions_Score' by 'Intervention'
library(dplyr)
summary_stats <- df_clean %>%
group_by(Intervention) %>%
summarise(
Mean = mean(Intervention_Questions_Score, na.rm = TRUE),
SD = sd(Intervention_Questions_Score, na.rm = TRUE),
Min = min(Intervention_Questions_Score, na.rm = TRUE),
Max = max(Intervention_Questions_Score, na.rm = TRUE)
)
# Display the summary statistics
print(summary_stats)
# Compute the mean and SD for each group
summary_stats <- df_clean %>%
group_by(Intervention) %>%
summarise(
Mean = mean(Intervention_Questions_Score, na.rm = TRUE),
SD = sd(Intervention_Questions_Score, na.rm = TRUE)
)
# Merge the summary statistics back with the original data
df_clean <- df_clean %>%
left_join(summary_stats, by = "Intervention") %>%
mutate(
Is_Outlier = Intervention_Questions_Score < (Mean - 2 * SD) | Intervention_Questions_Score > (Mean + 2 * SD)
) %>%
select(-Mean, -SD)  # Remove the temporary mean and SD columns
# Filter rows where Is_Outlier is TRUE
outliers <- df_clean %>%
filter(Is_Outlier == TRUE)
select(Participant)
colnames(df_clean)
# Ensure 'Intervention_Questions_Score' is numeric and remove invalid rows
df$Intervention_Questions_Score <- as.numeric(df$Intervention_Questions_Score)
df_clean <- na.omit(df)  # Remove rows with NA in any column
# Generate summary statistics for 'Intervention_Questions_Score' by 'Intervention'
library(dplyr)
summary_stats <- df_clean %>%
group_by(Intervention) %>%
summarise(
Mean = mean(Intervention_Questions_Score, na.rm = TRUE),
SD = sd(Intervention_Questions_Score, na.rm = TRUE),
Min = min(Intervention_Questions_Score, na.rm = TRUE),
Max = max(Intervention_Questions_Score, na.rm = TRUE)
)
# Display the summary statistics
print(summary_stats)
# Compute the mean and SD for each group
summary_stats <- df_clean %>%
group_by(Intervention) %>%
summarise(
Mean = mean(Intervention_Questions_Score, na.rm = TRUE),
SD = sd(Intervention_Questions_Score, na.rm = TRUE)
)
# Merge the summary statistics back with the original data
df_clean <- df_clean %>%
left_join(summary_stats, by = "Intervention") %>%
mutate(
Is_Outlier = Intervention_Questions_Score < (Mean - 2 * SD) | Intervention_Questions_Score > (Mean + 2 * SD)
) %>%
select(-Mean, -SD)  # Remove the temporary mean and SD columns
# Filter rows where Is_Outlier is TRUE
outliers <- df_clean %>%
filter(Is_Outlier == TRUE)
dplyr::select(Participant)
# Ensure 'Intervention_Questions_Score' is numeric and remove invalid rows
df$Intervention_Questions_Score <- as.numeric(df$Intervention_Questions_Score)
df_clean <- na.omit(df)  # Remove rows with NA in any column
# Generate summary statistics for 'Intervention_Questions_Score' by 'Intervention'
library(dplyr)
summary_stats <- df_clean %>%
group_by(Intervention) %>%
summarise(
Mean = mean(Intervention_Questions_Score, na.rm = TRUE),
SD = sd(Intervention_Questions_Score, na.rm = TRUE),
Min = min(Intervention_Questions_Score, na.rm = TRUE),
Max = max(Intervention_Questions_Score, na.rm = TRUE)
)
# Display the summary statistics
print(summary_stats)
# Compute the mean and SD for each group
summary_stats <- df_clean %>%
group_by(Intervention) %>%
summarise(
Mean = mean(Intervention_Questions_Score, na.rm = TRUE),
SD = sd(Intervention_Questions_Score, na.rm = TRUE)
)
# Merge the summary statistics back with the original data
df_clean <- df_clean %>%
left_join(summary_stats, by = "Intervention") %>%
mutate(
Is_Outlier = Intervention_Questions_Score < (Mean - 2 * SD) | Intervention_Questions_Score > (Mean + 2 * SD)
) %>%
select(-Mean, -SD)  # Remove the temporary mean and SD columns
# Filter rows where Is_Outlier is TRUE
outliers <- df_clean %>%
filter(Is_Outlier == TRUE)
# Print the outliers
print(outliers$Participant)
